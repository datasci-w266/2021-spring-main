{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side Notebook: Classification and Masked Language Models\n",
    "\n",
    "This is inspired by and aligned with the paper: **“Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference”**, by Timo Schick, Hinrich Schuetze (https://arxiv.org/pdf/2001.07676.pdf). See also Joachim\\'s paper reading session on Thursday, 03/18, noon.\n",
    "\n",
    "The idea is to use the intrinsic knowledge of pre-trained language models to 'prime' the classification task. This approach can improve classification performance when there are few training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForMaskedLM\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c51d345e7da419daa3a08c8d8722036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f8b486267840eb87e90e081d5ac102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32449717166046ac8ee6ccf368aec5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/527M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = TFBertForMaskedLM.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at an example of how the masked language model works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"The capital of France is [MASK].\", return_tensors=\"tf\")\n",
    "mask_position = np.where(inputs['input_ids'] == 103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), array([6]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2123"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model(inputs)[0][0, mask_position[1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(2123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! The language model figured that out.\n",
    "\n",
    "Let's now look at three fake tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\"This flick was really bad. Poor acting.\", \n",
    "          \"This joint was absolutely terrific. Great! Really nice flavors!\", \n",
    "          \"My meal at the place was terribly prepared. Way too spicey.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**:\n",
    " * Can you classify these tweets without further information?\n",
    " * How would we generally use BERT for these types of classification tasks?\n",
    " * What is the challenge with this approach, particularly given there are few examples?\n",
    " * Is there maybe a way to use masked language models to help?\n",
    " \n",
    " \n",
    "Obviously... one cannot simply say \"I'm going to classify\". Classify what?  You need to know what the domain/question really is. 'Is the tweet about restaurants or movies' would be quite different from a sentiment classification.\n",
    "\n",
    "So... can we use masked LMs? \n",
    "\n",
    "Yes... the idea is to augment the actual text with a **probing question** that includes a **masked token that is to be predicted**. And you compare here the likelihood of **words that represent the classes**. I.e., for each task you need to define a (or multiple) probing question and the words that represent the classes.\n",
    "\n",
    "Examples:\n",
    "\n",
    " *  Topic classification: **\"This movie was really bad. Poor acting.\"** $\\rightarrow$ **\"This movie was really bad. Poor acting. *This sentence talks about [MASK]*\"** where you want the LM to predict which word of your class representatives **'restaurants' or 'movies'** is more likely for the [MASK] token prediction.\n",
    " \n",
    " \n",
    "  *  Sentiment classifications: **\"This movie was really bad. Poor acting.\"** $\\rightarrow$ **\"This movie was really bad. Poor acting. *I had a [MASK] experience.*\"** where you want the LM to predict which word of your class representatives **'good' or 'bad'** is more likely for the [MASK] token prediction.\n",
    "\n",
    "\n",
    "\n",
    "Let's try easy examples for two classification tasks for our tweets:\n",
    "\n",
    "1) Does the tweet refer to restaurants or movies   \n",
    "2) Is the sentiment positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"This flick was really bad. Poor acting. The previous phrase talked about [MASK].\"\n",
      "Logits:\n",
      "\trestaurants:  0.0086269155\n",
      "\tmovies:  5.537849\n",
      "\n",
      "\"This joint was absolutely terrific. Great! Really nice flavors! The previous phrase talked about [MASK].\"\n",
      "Logits:\n",
      "\trestaurants:  3.5222921\n",
      "\tmovies:  2.9667614\n",
      "\n",
      "\"My meal at the place was terribly prepared. Way too spicey. The previous phrase talked about [MASK].\"\n",
      "Logits:\n",
      "\trestaurants:  3.9967456\n",
      "\tmovies:  2.4576795\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test_phrase = \" I had a [MASK] experience.\"\n",
    "test_phrase = \" The previous phrase talked about [MASK].\"\n",
    "\n",
    "#pair = ['good', 'bad']\n",
    "pair = ['restaurants', 'movies']\n",
    "\n",
    "tweets_pet = [x + test_phrase for x in tweets]\n",
    "\n",
    "inputs = tokenizer(tweets_pet, padding=True, return_tensors=\"tf\")\n",
    "\n",
    "mask_positions = np.where(inputs['input_ids'] == 103)\n",
    "\n",
    "out = model(inputs)\n",
    "\n",
    "\n",
    "pair_tokens = tokenizer.convert_tokens_to_ids(pair)\n",
    "\n",
    "\n",
    "for example_nr, example in enumerate(tweets_pet):\n",
    "    print('\"' + example + '\"')\n",
    "    print('Logits:')\n",
    "\n",
    "    print('\\t' + pair[0] + ': ', out[0][example_nr, mask_positions[1][example_nr]][pair_tokens[0]].numpy())\n",
    "    print('\\t' + pair[1] + ': ', out[0][example_nr, mask_positions[1][example_nr]][pair_tokens[1]].numpy())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Looks like we got perfect zero-shot performance by exploiting the knowledge of the masked language model! (I.e., the logit for the correct class was the higher one.)\n",
    "\n",
    "Now we do the same for the sentiment classification. For that, we need to swap the probing question and the answer pair that represents the task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"This flick was really bad. Poor acting. I had a [MASK] experience.\"\n",
      "Logits:\n",
      "\tgood:  9.79245\n",
      "\tbad:  13.258743\n",
      "\n",
      "\"This joint was absolutely terrific. Great! Really nice flavors! I had a [MASK] experience.\"\n",
      "Logits:\n",
      "\tgood:  9.051356\n",
      "\tbad:  8.38979\n",
      "\n",
      "\"My meal at the place was terribly prepared. Way too spicey. I had a [MASK] experience.\"\n",
      "Logits:\n",
      "\tgood:  8.767116\n",
      "\tbad:  10.673337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_phrase = \" I had a [MASK] experience.\"\n",
    "#test_phrase = \" This sentence talks about [MASK].\"\n",
    "\n",
    "pair = ['good', 'bad']\n",
    "#pair = ['restaurants', 'movies']\n",
    "\n",
    "tweets_pet = [x + test_phrase for x in tweets]\n",
    "\n",
    "inputs = tokenizer(tweets_pet, padding=True, return_tensors=\"tf\")\n",
    "\n",
    "mask_positions = np.where(inputs['input_ids'] == 103)\n",
    "\n",
    "out = model(inputs)\n",
    "\n",
    "\n",
    "pair_tokens = tokenizer.convert_tokens_to_ids(pair)\n",
    "\n",
    "\n",
    "for example_nr, example in enumerate(tweets_pet):\n",
    "    print('\"' + example + '\"')\n",
    "    print('Logits:')\n",
    "\n",
    "    print('\\t' + pair[0] + ': ', out[0][example_nr, mask_positions[1][example_nr]][pair_tokens[0]].numpy())\n",
    "    print('\\t' + pair[1] + ': ', out[0][example_nr, mask_positions[1][example_nr]][pair_tokens[1]].numpy())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again are all of the classes correct! \n",
    "\n",
    "So for this simple setup we got zero-shot classification accuracy for both classification tasks by selecting a suitable probing question and a suitable word pair that represents the two classes.  \n",
    "\n",
    "But be careful... things can be a lot less good even in situations where one would think it should be a no-brainer for the LM.\n",
    "\n",
    "Let's play around a bit.\n",
    "\n",
    "**Further Questions**:\n",
    " * Any surprises in the above outcomes? \n",
    " * Are there other ways to encode the information + test phrase for BERT? \n",
    " * Would this also work for more than 2 classes? What would change?\n",
    " * What can be difficulties with this approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
