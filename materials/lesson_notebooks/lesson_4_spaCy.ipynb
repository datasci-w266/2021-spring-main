{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Very Basic spaCy Examples\n",
    "\n",
    "spaCy is an open source industrial strength NLP engine that can perform multiple functions out of the box. It strikes a good balance between speed of processing and accuracy of predictions.  It comes with a number of different language models trained on the [OntoNotes5](https://catalog.ldc.upenn.edu/LDC2013T19) data set.  This means that it is already trained to do part of speech tagging, dependency parsing, semantic role labeling, coreference resolution, and entity detection.  It can also be trained to do classification and a number of other tasks in the standard NLP stack.  It is very fast.  It can be a handy way of analyzing some text. Another use is annotating some text to then create a labelled training set that you use to train up your own model independent of spaCy.\n",
    "\n",
    "It has also been pre-trained on multiple languages.  When using it you need to select and load a specific language model.\n",
    "\n",
    "spaCy uses a combination of techniques including embeddings and convolutional neural nets.  There's a video of [Matthew Honnibal](https://spacy.io/universe/project/video-spacys-ner-model) (at 10:00) describing how Spacy performs named entity recogntion.  He describes the architecutal choices he made in adding the functionality.  You can also add your own training on top of the existing training to enhance the model.\n",
    "\n",
    "Take a look at [this page](https://spacy.io/usage) on the spaCy website to see if you can run it on your machine.  It works on Linux, Mac, and Windows and will operate quite well on a machine without a GPU.  Eventhough it uses Cython you can use pip or conda to install a working package that doesn't require you to run a C compiler.\n",
    "\n",
    "In order to use this notebook, you'll need to install spaCy on your machine.  If you're just experimenting, it is a good idea to use something like the virtualenv to install this so it will not adversely affect your existing set up.\n",
    "\n",
    "Here are the steps, repeated from [this spaCy page](https://spacy.io/usage):\n",
    "\n",
    "#### setup is simple when you create a virtual environment\n",
    "1. make virtualenv\n",
    "2. source .env/bin/activate\n",
    "3. pip install -U spacy\n",
    "4. pip install -U spacy-lookups-data\n",
    "\n",
    "#### get the large english model (it comes with pre-trained embeddings)\n",
    "- python -m spacy download en_core_web_lg\n",
    "\n",
    "#### if you haven't already you should also install pandas so you can capture data for subsequent analysis and use\n",
    "- pip install pandas\n",
    "\n",
    "##### you can also make a special kernel in your jupyter notebook so you know you're running the right environment.\n",
    "##### you can create that in your virtualenv\n",
    "\n",
    "###### to create the kernel for your notebook\n",
    "- python -m ipykernel install --user --name spacy23 --display-name \"Python 3 Spacy2.3\"\n",
    "###### it will tell you it has created the kernel\n",
    "Installed kernelspec spacy23 in /Users/markhb/Library/Jupyter/kernels/spacy23\n",
    "\n",
    "#### if you want to get a specific version of a language model\n",
    "- python -m spacy download en_core_web_sm-2.1.0 --direct\n",
    "\n",
    "#### if you want to get a non-english model e.g. japanese model\n",
    "- python -m spacy download ja_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n",
      "1.1.2\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "print(spacy.__version__)\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained Language Models\n",
    "Make sure you first load a language model. We're selecting English via the large model which gives us access to embeddings.  There are many other options and other languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load an english model -- the large model includes word embeddings\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing\n",
    "When you invoke spaCy with some input text it generates a set of objects.  spaCy wants to process \"document\" like objects. This document can be a sentence or can be many sentences.  You provide text and spaCy runs the nlp function which returns a Doc object.  That Doc object contains a list of Token objects each of which is associated with a set of annotations.  Many examples below are just about harvesting the labels associated with each token after the processing of the Document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first word is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u\"This is a sentence.\")\n",
    "\n",
    "print(\"The first word is: \") \n",
    "doc[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9510932235818049"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We're taking advantage of the large model which uses embeddings \n",
    "#This means we can compute the similarity of two sentences and synonymous words have similar embeddings\n",
    "doc1 = nlp(\"How do I adopt a cat?\")\n",
    "doc2 = nlp(\"How do I obtain a pet?\")\n",
    "\n",
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8914506294237656"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Because this is word based (even with the underlying embeddings) and not a sentence based set of embeddings \n",
    "#these semantically similar sentences aren't as similar as you might expect.\n",
    "doc3 = nlp(\"How old are you?\")\n",
    "doc4 = nlp(\"What is your age?\")\n",
    "\n",
    "doc3.similarity(doc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple functions\n",
    "Spacy is able to perform multiple functions that you might expect from an NLP stack.  Here are examples of some of those functions.  These functions include sentence boundary detection, lemmatization, part of speech tagging,\n",
    "rule based matching, dependency parsing, noun phrase detection, and named entity recognition.  All of this functionality is combined under one umbrella."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Boundary Detection\n",
    "\n",
    "Sentence boundary detection is a hard problem because you can't just look for a period. Abbreviations can contain periods.  Often times, but not always, the boundary of a sentence is a period followed by a space or two and then a capital letter.  A well trained classifier can handle the many possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence boundary detection is actually a pretty hard problem.  \n",
      "Great advances have been made in the U.S. in the past decade.\n",
      "New neural nets like a CNN can help improve results on this classification task.\n"
     ]
    }
   ],
   "source": [
    "#sentence detection\n",
    "# Given an input block of text, identify where the sentences end.\n",
    "\n",
    "about_text = ('Sentence boundary detection is actually'\n",
    "              ' a pretty hard problem.  Great advances'\n",
    "              ' have been made in the U.S. in the past decade. New neural nets'\n",
    "              ' like a CNN can help improve results on this classification task.')\n",
    "about_doc = nlp(about_text)\n",
    "sentences = list(about_doc.sents)\n",
    "#len(sentences)\n",
    "\n",
    "#now print out the sentences\n",
    "for sentence in sentences:\n",
    "    print (sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "Lemmatization is the identification of the root form of a word.  This means that plural nouns are converted to their signular form.  Similarly a verb is converted to its infinitive form.  It can be useful when you want to count up word occurences and want to consolidate different forms of the same word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We -PRON-\n",
      "are be\n",
      "helping help\n",
      "organize organize\n",
      "all all\n",
      "of of\n",
      "the the\n",
      "conference conference\n",
      "papers paper\n",
      "on on\n",
      "Natural Natural\n",
      "Language Language\n",
      "Processing processing\n",
      "from from\n",
      "all all\n",
      "conferences conference\n",
      ". .\n",
      "We -PRON-\n",
      "keep keep\n",
      "clustering cluster\n",
      "the the\n",
      "papers paper\n",
      "in in\n",
      "to to\n",
      "different different\n",
      "sets set\n",
      "of of\n",
      "subdomains subdomain\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "#lemmatization\n",
    "#since each token is a word you can just print the lemma after the word even though it doesn't look great\n",
    "organize_papers_text = ('We are helping organize all of the'\n",
    "    ' conference papers on Natural Language'\n",
    "    ' Processing from all conferences. We keep clustering the papers'\n",
    "    ' in to different sets of subdomains.')\n",
    "organize_papers_doc = nlp(organize_papers_text)\n",
    "\n",
    "#print out each token and its associated lemma\n",
    "for token in organize_papers_doc:\n",
    "    print (token, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech Tagging\n",
    "Part of speech tagging can be very valuable.  Tagging words can allow you to quickly distinguish \"things\" from \"actions\" or \"events.\" spaCy has several different tags to display related to part of speech as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence NN NOUN noun, singular or mass\n",
      "boundary JJ ADJ adjective\n",
      "detection NN NOUN noun, singular or mass\n",
      "is VBZ AUX verb, 3rd person singular present\n",
      "actually RB ADV adverb\n",
      "a DT DET determiner\n",
      "pretty RB ADV adverb\n",
      "hard JJ ADJ adjective\n",
      "problem NN NOUN noun, singular or mass\n",
      ". . PUNCT punctuation mark, sentence closer\n",
      "  _SP SPACE None\n",
      "Great JJ ADJ adjective\n",
      "advances NNS NOUN noun, plural\n",
      "have VBP AUX verb, non-3rd person singular present\n",
      "been VBN AUX verb, past participle\n",
      "made VBN VERB verb, past participle\n",
      "in IN ADP conjunction, subordinating or preposition\n",
      "the DT DET determiner\n",
      "U.S. NNP PROPN noun, proper singular\n",
      "in IN ADP conjunction, subordinating or preposition\n",
      "the DT DET determiner\n",
      "past JJ ADJ adjective\n",
      "decade NN NOUN noun, singular or mass\n",
      ". . PUNCT punctuation mark, sentence closer\n",
      "New JJ ADJ adjective\n",
      "neural JJ ADJ adjective\n",
      "nets NNS NOUN noun, plural\n",
      "like IN SCONJ conjunction, subordinating or preposition\n",
      "a DT DET determiner\n",
      "CNN NNP PROPN noun, proper singular\n",
      "can MD VERB verb, modal auxiliary\n",
      "help VB VERB verb, base form\n",
      "improve VB VERB verb, base form\n",
      "results NNS NOUN noun, plural\n",
      "on IN ADP conjunction, subordinating or preposition\n",
      "this DT DET determiner\n",
      "classification NN NOUN noun, singular or mass\n",
      "task NN NOUN noun, singular or mass\n",
      ". . PUNCT punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "#POS with unpretty print\n",
    "\n",
    "for token in about_doc:\n",
    "    print (token, token.tag_, token.pos_, spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "      <th>pos</th>\n",
       "      <th>explain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boundary</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>detection</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>AUX</td>\n",
       "      <td>verb, 3rd person singular present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actually</td>\n",
       "      <td>RB</td>\n",
       "      <td>ADV</td>\n",
       "      <td>adverb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "      <td>determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pretty</td>\n",
       "      <td>RB</td>\n",
       "      <td>ADV</td>\n",
       "      <td>adverb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hard</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>problem</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punctuation mark, sentence closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>_SP</td>\n",
       "      <td>SPACE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Great</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>advances</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun, plural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>AUX</td>\n",
       "      <td>verb, non-3rd person singular present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>been</td>\n",
       "      <td>VBN</td>\n",
       "      <td>AUX</td>\n",
       "      <td>verb, past participle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>made</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>verb, past participle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>conjunction, subordinating or preposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "      <td>determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>noun, proper singular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>conjunction, subordinating or preposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "      <td>determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>past</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>decade</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punctuation mark, sentence closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>New</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>neural</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nets</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun, plural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>like</td>\n",
       "      <td>IN</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>conjunction, subordinating or preposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>a</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "      <td>determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CNN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>noun, proper singular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>can</td>\n",
       "      <td>MD</td>\n",
       "      <td>VERB</td>\n",
       "      <td>verb, modal auxiliary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>help</td>\n",
       "      <td>VB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>verb, base form</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>improve</td>\n",
       "      <td>VB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>verb, base form</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>results</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun, plural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>on</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>conjunction, subordinating or preposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>this</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "      <td>determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>classification</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>task</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punctuation mark, sentence closer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              text  tag    pos                                    explain\n",
       "0         Sentence   NN   NOUN                     noun, singular or mass\n",
       "1         boundary   JJ    ADJ                                  adjective\n",
       "2        detection   NN   NOUN                     noun, singular or mass\n",
       "3               is  VBZ    AUX          verb, 3rd person singular present\n",
       "4         actually   RB    ADV                                     adverb\n",
       "5                a   DT    DET                                 determiner\n",
       "6           pretty   RB    ADV                                     adverb\n",
       "7             hard   JJ    ADJ                                  adjective\n",
       "8          problem   NN   NOUN                     noun, singular or mass\n",
       "9                .    .  PUNCT          punctuation mark, sentence closer\n",
       "10                  _SP  SPACE                                       None\n",
       "11           Great   JJ    ADJ                                  adjective\n",
       "12        advances  NNS   NOUN                               noun, plural\n",
       "13            have  VBP    AUX      verb, non-3rd person singular present\n",
       "14            been  VBN    AUX                      verb, past participle\n",
       "15            made  VBN   VERB                      verb, past participle\n",
       "16              in   IN    ADP  conjunction, subordinating or preposition\n",
       "17             the   DT    DET                                 determiner\n",
       "18            U.S.  NNP  PROPN                      noun, proper singular\n",
       "19              in   IN    ADP  conjunction, subordinating or preposition\n",
       "20             the   DT    DET                                 determiner\n",
       "21            past   JJ    ADJ                                  adjective\n",
       "22          decade   NN   NOUN                     noun, singular or mass\n",
       "23               .    .  PUNCT          punctuation mark, sentence closer\n",
       "24             New   JJ    ADJ                                  adjective\n",
       "25          neural   JJ    ADJ                                  adjective\n",
       "26            nets  NNS   NOUN                               noun, plural\n",
       "27            like   IN  SCONJ  conjunction, subordinating or preposition\n",
       "28               a   DT    DET                                 determiner\n",
       "29             CNN  NNP  PROPN                      noun, proper singular\n",
       "30             can   MD   VERB                      verb, modal auxiliary\n",
       "31            help   VB   VERB                            verb, base form\n",
       "32         improve   VB   VERB                            verb, base form\n",
       "33         results  NNS   NOUN                               noun, plural\n",
       "34              on   IN    ADP  conjunction, subordinating or preposition\n",
       "35            this   DT    DET                                 determiner\n",
       "36  classification   NN   NOUN                     noun, singular or mass\n",
       "37            task   NN   NOUN                     noun, singular or mass\n",
       "38               .    .  PUNCT          punctuation mark, sentence closer"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#POS\n",
    "#capturing the output in a pandas dataframe makes it easier to view\n",
    "dpos = pd.DataFrame()\n",
    "dpos['text'] = [token.text for token in about_doc]\n",
    "dpos['tag'] = [token.tag_ for token in about_doc]\n",
    "dpos['pos'] = [token.pos_ for token in about_doc]\n",
    "dpos['explain'] = [spacy.explain(token.tag_) for token in about_doc]\n",
    "\n",
    "dpos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule-Based Matching\n",
    "spaCy offers a rule based matching capability that allows you to construct rules to match strings and extract them.  This works well if you know all the things you're looking for like an unambigious list of your company's product names.  This just picks out the first proper noun followed by another proper noun. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Marti Hearst'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rule based matching\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "nnp_doc = nlp('Marti Hearst and Dan Jurafsky studied with Robert Wilensky at UC Berkeley.')\n",
    "\n",
    "def extract_full_name(nlp_doc):\n",
    "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "    matcher.add('FULL_NAME', None, pattern)\n",
    "    matches = matcher(nlp_doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_doc[start:end]\n",
    "        return span.text\n",
    "\n",
    "extract_full_name(nnp_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Parsing\n",
    "spaCy performs dependency parsing right out of the box.  This can be a very handy way of identifying words and the relations between them.  Sometimes those relations fundamentally change the meaning of the word as in the case of negation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students NNS learning nsubj\n",
      "are VBP learning aux\n",
      "learning VBG learning ROOT\n",
      "Natural NNP Language compound\n",
      "Language NNP Processing compound\n",
      "Processing NNP learning dobj\n",
      "in IN learning prep\n",
      "the DT class det\n",
      "W266 NNP class compound\n",
      "class NN in pobj\n",
      ". . learning punct\n"
     ]
    }
   ],
   "source": [
    "#dependency parsing\n",
    "w266_text = 'Students are learning Natural Language Processing in the W266 class.'\n",
    "w266_doc = nlp(w266_text)\n",
    "for token in w266_doc:\n",
    "    print (token.text, token.tag_, token.head.text, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students student NOUN NNS nsubj Xxxxx True False\n",
      "are be AUX VBP aux xxx True True\n",
      "learning learn VERB VBG ROOT xxxx True False\n",
      "Natural Natural PROPN NNP compound Xxxxx True False\n",
      "Language Language PROPN NNP compound Xxxxx True False\n",
      "Processing Processing PROPN NNP dobj Xxxxx True False\n",
      "in in ADP IN prep xx True True\n",
      "the the DET DT det xxx True True\n",
      "W266 W266 PROPN NNP compound Xddd False False\n",
      "class class NOUN NN pobj xxxx True False\n",
      ". . PUNCT . punct . False False\n"
     ]
    }
   ],
   "source": [
    "# more parsing labels - same w266_doc\n",
    "# you can extract many labels for use in downstream processes\n",
    "for token in w266_doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>is_punctuation</th>\n",
       "      <th>is_space</th>\n",
       "      <th>shape</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>head</th>\n",
       "      <th>dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Students</td>\n",
       "      <td>student</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>learning</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>are</td>\n",
       "      <td>be</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxx</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBP</td>\n",
       "      <td>learning</td>\n",
       "      <td>aux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>learning</td>\n",
       "      <td>learn</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>learning</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natural</td>\n",
       "      <td>Natural</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Language</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Language</td>\n",
       "      <td>Language</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Processing</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Processing</td>\n",
       "      <td>Processing</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>learning</td>\n",
       "      <td>dobj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xx</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>learning</td>\n",
       "      <td>prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxx</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>class</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>W266</td>\n",
       "      <td>W266</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Xddd</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>class</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>class</td>\n",
       "      <td>class</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>in</td>\n",
       "      <td>pobj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>learning</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text       lemma  is_punctuation  is_space  shape part_of_speech  \\\n",
       "0     Students     student           False     False  Xxxxx           NOUN   \n",
       "1          are          be           False     False    xxx            AUX   \n",
       "2     learning       learn           False     False   xxxx           VERB   \n",
       "3      Natural     Natural           False     False  Xxxxx          PROPN   \n",
       "4     Language    Language           False     False  Xxxxx          PROPN   \n",
       "5   Processing  Processing           False     False  Xxxxx          PROPN   \n",
       "6           in          in           False     False     xx            ADP   \n",
       "7          the         the           False     False    xxx            DET   \n",
       "8         W266        W266           False     False   Xddd          PROPN   \n",
       "9        class       class           False     False   xxxx           NOUN   \n",
       "10           .           .            True     False      .          PUNCT   \n",
       "\n",
       "   pos_tag        head       dep  \n",
       "0      NNS    learning     nsubj  \n",
       "1      VBP    learning       aux  \n",
       "2      VBG    learning      ROOT  \n",
       "3      NNP    Language  compound  \n",
       "4      NNP  Processing  compound  \n",
       "5      NNP    learning      dobj  \n",
       "6       IN    learning      prep  \n",
       "7       DT       class       det  \n",
       "8      NNP       class  compound  \n",
       "9       NN          in      pobj  \n",
       "10       .    learning     punct  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you capture the tags in a dataframe you can then perform additional \n",
    "#operations like counting and filtering and searching\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = [token.text for token in w266_doc]\n",
    "df['lemma'] = [token.lemma_ for token in w266_doc]\n",
    "df['is_punctuation'] = [token.is_punct for token in w266_doc]\n",
    "df['is_space'] = [token.is_space for token in w266_doc]\n",
    "df['shape'] = [token.shape_ for token in w266_doc]\n",
    "df['part_of_speech'] = [token.pos_ for token in w266_doc]\n",
    "df['pos_tag'] = [token.tag_ for token in w266_doc]\n",
    "df['head'] = [token.head.text for token in w266_doc] \n",
    "df['dep'] = [token.dep_ for token in w266_doc]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun Phrase Detection\n",
    "spaCy can identify the noun phrases in the input text.  This can be an interesting set of objects to count if you're doing some basic analytics.  If you simply grabbed bi-grams you would introduce a lot of noise and miss some important parts of phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students\n",
      "Natural Language Processing\n",
      "the W266 class\n"
     ]
    }
   ],
   "source": [
    "#noun phrase detection\n",
    "\n",
    "for chunk in w266_doc.noun_chunks:\n",
    "    print (chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recogntion\n",
    "spaCy is also trained to do some basic NER out of the box.  It has been trained using OntoNotes5 so you can see the set of entity tags it uses to annotate its content.  If those don't work for you, then you can train spaCy to identify different entities or use a different tag set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marti Hearst 0 12 PERSON People, including fictional\n",
      "Dan Jurafsky 17 29 PERSON People, including fictional\n",
      "Robert Wilensky 43 58 PERSON People, including fictional\n",
      "UC Berkeley 62 73 ORG Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "#NER example\n",
    "for ent in nnp_doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char,\n",
    "        ent.label_, spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVO Triple Extraction example\n",
    "You can leverage the dependency graph to identify subject-verb-object triples.  These can be used to populate a knowledge graph or to extract \"facts\" from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Students POS: NOUN, dep: nsubj\n",
      "Token are POS: AUX, dep: aux\n",
      "Token learning POS: VERB, dep: ROOT\n",
      "Token Natural POS: PROPN, dep: compound\n",
      "Token Language POS: PROPN, dep: compound\n",
      "Token Processing POS: PROPN, dep: dobj\n",
      "Token in POS: ADP, dep: prep\n",
      "Token the POS: DET, dep: det\n",
      "Token W266 POS: PROPN, dep: compound\n",
      "Token class POS: NOUN, dep: pobj\n",
      "Token . POS: PUNCT, dep: punct\n",
      "svo triple:, subject: students, verb: learning, attribute: language processing\n"
     ]
    }
   ],
   "source": [
    "#SVO extraction\n",
    "\n",
    "# object and subject constants\n",
    "OBJECT_DEPS = {\"dobj\", \"dative\", \"attr\", \"oprd\"}\n",
    "SUBJECT_DEPS = {\"nsubj\", \"nsubjpass\", \"csubj\", \"agent\", \"expl\"}\n",
    "\n",
    "# extract the subject, object and verb from the input\n",
    "def extract_triples(doc):\n",
    "    sub = []\n",
    "    at = []\n",
    "    ve = []\n",
    "    for token in doc:\n",
    "        # is this a verb?\n",
    "        if token.pos_ == \"VERB\":\n",
    "            ve.append(token.text)\n",
    "        # is this the object?\n",
    "        if token.dep_ in OBJECT_DEPS or token.head.dep_ in OBJECT_DEPS:\n",
    "            at.append(token.text)\n",
    "        # is this the subject?\n",
    "        if token.dep_ in SUBJECT_DEPS or token.head.dep_ in SUBJECT_DEPS:\n",
    "            sub.append(token.text)\n",
    "    return \" \".join(sub).strip().lower(), \" \".join(ve).strip().lower(), \" \".join(at).strip().lower()\n",
    "\n",
    "\n",
    "# print out the pos and deps\n",
    "for token in w266_doc:\n",
    "    print(\"Token {} POS: {}, dep: {}\".format(token.text, token.pos_, token.dep_))\n",
    "\n",
    "# process the input information\n",
    "subject, verb, attribute = extract_triples(w266_doc)\n",
    "print(\"svo triple:, subject: {}, verb: {}, attribute: {}\".format(subject, verb, attribute))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Identification\n",
    "\n",
    "spaCy can also be used to identify questions in text.  Question can be yes/no questions like \"Do you...\" or \"Can you...\" or \"Will you...\"  Question can also use a wh- word like who, what, where, when, or how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token What POS: PRON, dep: attr\n",
      "Token are POS: AUX, dep: ROOT\n",
      "Token students POS: NOUN, dep: nsubj\n",
      "Token learning POS: VERB, dep: acl\n",
      "Token in POS: ADP, dep: prep\n",
      "Token the POS: DET, dep: det\n",
      "Token W266 POS: PROPN, dep: compound\n",
      "Token class POS: NOUN, dep: pobj\n",
      "Token ? POS: PUNCT, dep: punct\n",
      "question type: what\n"
     ]
    }
   ],
   "source": [
    "#question identification\n",
    "w266_qtext = 'What are students learning in the W266 class?'\n",
    "#w266_qtext = 'Do students learn natural language processing in the W266 class?'\n",
    "w266_question = nlp(w266_qtext)\n",
    "\n",
    "\n",
    "# tags that define wether the word is wh-\n",
    "WH_WORDS = {\"WP\", \"WP$\", \"WRB\"}\n",
    "\n",
    "\n",
    "# whether the doc is a question, as well as the wh-word if any\n",
    "def is_question(doc):\n",
    "    # is the first token a verb?\n",
    "    if len(doc) > 0 and doc[0].pos_ == \"AUX\":  # covers both auxiliary & modal verbs\n",
    "        return True, \"yes/no question\"\n",
    "    # go over all words\n",
    "    for token in doc:\n",
    "        # is it a wh- word?\n",
    "        if token.tag_ in WH_WORDS:\n",
    "            return True, token.text.lower()\n",
    "    return False, \"\"\n",
    "\n",
    "\n",
    "for token in w266_question:\n",
    "    print(\"Token {} POS: {}, dep: {}\".format(token.text, token.pos_, token.dep_))\n",
    "\n",
    "# test the input statement\n",
    "question, wh_word = is_question(w266_question)\n",
    "print(\"question type: {}\".format(wh_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 Spacy2.3",
   "language": "python",
   "name": "spacy23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
